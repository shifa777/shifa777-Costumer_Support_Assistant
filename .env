# Ollama Configuration
OLLAMA_API_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:4b

# Embedding Configuration
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DEVICE=cuda  # Use 'cpu' if GPU not available

# Vector Database
CHROMA_DB_PATH=./chroma_db_rooman
COLLECTION_NAME=rooman_faqs

# Dataset Configuration
FAQ_DATABASE_PATH=C:\Users\imran\OneDrive\Desktop\rag\json\faq_database.json

# Text Splitting Configuration
CHUNK_SIZE=20000
CHUNK_OVERLAP=4000

# RAG Configuration
TOP_K_RESULTS=5
CONFIDENCE_THRESHOLD=0.7  # Escalate if confidence below this
SIMILARITY_THRESHOLD=0.6  # Minimum similarity score to consider relevant

# Application Settings
APP_TITLE=Rooman SupportAssistant
APP_ICON=ðŸŽ“
LOG_LEVEL=INFO
